{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1fkReFX1u6f0IdZ5mJ-rgle7Z0Loajc5s",
      "authorship_tag": "ABX9TyMw0CCzIY6dMOKci/IRVupK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivanshudwivedi/Deep-Learning/blob/main/TenserFlow_Notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#Create 2 constant matrices\n",
        "\n",
        "'''Creates a constant op that produces a 1x2 matrix. The op is added as a node to the default graph. The value returned by the constructor represents\n",
        "the output of the constant op. '''\n",
        "matrix1 = tf.constant([[3,3]])\n",
        "\n",
        "'''Creates a constant op that produces a 2x1 matrix. '''\n",
        "matrix2 = tf.constant([[2], [2]])\n",
        "\n",
        "#Matrix multiplication of 2 matrices\n",
        "'''Create a Matmul op that stores the matrix multiplication of the matrices 1 and 2'''\n",
        "product = tf.matmul(matrix1, matrix2)\n",
        "print(product)\n",
        "\n",
        "#Subtract 'a' from 'x'\n",
        "\n",
        "x = tf.Variable([1.0 , 3.0])\n",
        "a = tf.constant([3.0, 3.0])\n",
        "sub = tf.subtract(x, a)\n",
        "print(sub)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Nt5ZoOdOOrA",
        "outputId": "80be4125-266a-438e-fbb1-67eeddb3c0c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[12]], shape=(1, 1), dtype=int32)\n",
            "tf.Tensor([-2.  0.], shape=(2,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Simple Tensorfllow regression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "import pandas as pd\n",
        "import io\n",
        "import os\n",
        "import requests\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "\n",
        "df = pd.read_csv('/content/sample_data/california_housing_test.csv',\n",
        "                 na_values = ['NA', '?'])\n",
        "house = df['latitude']\n",
        "\n",
        "#Handle Missing Values by filling with median of that column\n",
        "df['latitude'] = df['latitude'].fillna(df['latitude'].median())\n",
        "print(df)\n",
        "\n",
        "#Pandas to NumPy\n",
        "x = df[['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'median_house_value']]\n",
        "y = df['latitude'].values\n",
        "\n",
        "#Building the Neural Network\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(25, input_dim = x.shape[1], activation = 'relu')) #Hidden Layer 1\n",
        "model.add(Dense(10, activation = 'relu')) #Hidden Layer 2\n",
        "model.add(Dense(1)) #Output Layer\n",
        "model.compile(loss = 'mean_squared_error', optimizer = 'adam') #Compiling the neural network\n",
        "model.fit(x, y, verbose = 2, epochs = 100) #Fitting the data and epochs means the number of iterations of training it goes through\n",
        "\n",
        "#Predicting the output using the model\n",
        "\n",
        "pred = model.predict(x)\n",
        "print(\"Predictions\", pred[0:10])\n",
        "\n",
        "#Measure RMSE to calculate the accuracy of the predictions\n",
        "score = np.sqrt(metrics.mean_squared_error(pred, y))\n",
        "print(\"Final Score: \", score)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7lzL9hgTqCT",
        "outputId": "438aa03f-418d-4778-9cb4-3797844571e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
            "0       -122.05     37.37                27.0       3885.0           661.0   \n",
            "1       -118.30     34.26                43.0       1510.0           310.0   \n",
            "2       -117.81     33.78                27.0       3589.0           507.0   \n",
            "3       -118.36     33.82                28.0         67.0            15.0   \n",
            "4       -119.67     36.33                19.0       1241.0           244.0   \n",
            "...         ...       ...                 ...          ...             ...   \n",
            "2995    -119.86     34.42                23.0       1450.0           642.0   \n",
            "2996    -118.14     34.06                27.0       5257.0          1082.0   \n",
            "2997    -119.70     36.30                10.0        956.0           201.0   \n",
            "2998    -117.12     34.10                40.0         96.0            14.0   \n",
            "2999    -119.63     34.42                42.0       1765.0           263.0   \n",
            "\n",
            "      population  households  median_income  median_house_value  \n",
            "0         1537.0       606.0         6.6085            344700.0  \n",
            "1          809.0       277.0         3.5990            176500.0  \n",
            "2         1484.0       495.0         5.7934            270500.0  \n",
            "3           49.0        11.0         6.1359            330000.0  \n",
            "4          850.0       237.0         2.9375             81700.0  \n",
            "...          ...         ...            ...                 ...  \n",
            "2995      1258.0       607.0         1.1790            225000.0  \n",
            "2996      3496.0      1036.0         3.3906            237200.0  \n",
            "2997       693.0       220.0         2.2895             62000.0  \n",
            "2998        46.0        14.0         3.2708            162500.0  \n",
            "2999       753.0       260.0         8.5608            500001.0  \n",
            "\n",
            "[3000 rows x 9 columns]\n",
            "Epoch 1/100\n",
            "94/94 - 2s - loss: 275180608.0000 - 2s/epoch - 16ms/step\n",
            "Epoch 2/100\n",
            "94/94 - 0s - loss: 883071.7500 - 216ms/epoch - 2ms/step\n",
            "Epoch 3/100\n",
            "94/94 - 0s - loss: 686477.5000 - 236ms/epoch - 3ms/step\n",
            "Epoch 4/100\n",
            "94/94 - 0s - loss: 509751.2188 - 134ms/epoch - 1ms/step\n",
            "Epoch 5/100\n",
            "94/94 - 0s - loss: 359178.5000 - 136ms/epoch - 1ms/step\n",
            "Epoch 6/100\n",
            "94/94 - 0s - loss: 242412.3125 - 131ms/epoch - 1ms/step\n",
            "Epoch 7/100\n",
            "94/94 - 0s - loss: 156127.6875 - 124ms/epoch - 1ms/step\n",
            "Epoch 8/100\n",
            "94/94 - 0s - loss: 95548.2734 - 143ms/epoch - 2ms/step\n",
            "Epoch 9/100\n",
            "94/94 - 0s - loss: 56169.7500 - 133ms/epoch - 1ms/step\n",
            "Epoch 10/100\n",
            "94/94 - 0s - loss: 32837.6211 - 132ms/epoch - 1ms/step\n",
            "Epoch 11/100\n",
            "94/94 - 0s - loss: 18887.6836 - 121ms/epoch - 1ms/step\n",
            "Epoch 12/100\n",
            "94/94 - 0s - loss: 11435.0869 - 130ms/epoch - 1ms/step\n",
            "Epoch 13/100\n",
            "94/94 - 0s - loss: 7541.5640 - 147ms/epoch - 2ms/step\n",
            "Epoch 14/100\n",
            "94/94 - 0s - loss: 5501.0903 - 141ms/epoch - 1ms/step\n",
            "Epoch 15/100\n",
            "94/94 - 0s - loss: 4492.1245 - 146ms/epoch - 2ms/step\n",
            "Epoch 16/100\n",
            "94/94 - 0s - loss: 4139.9746 - 144ms/epoch - 2ms/step\n",
            "Epoch 17/100\n",
            "94/94 - 0s - loss: 3843.0959 - 128ms/epoch - 1ms/step\n",
            "Epoch 18/100\n",
            "94/94 - 0s - loss: 3648.1243 - 128ms/epoch - 1ms/step\n",
            "Epoch 19/100\n",
            "94/94 - 0s - loss: 3616.2034 - 126ms/epoch - 1ms/step\n",
            "Epoch 20/100\n",
            "94/94 - 0s - loss: 3416.8857 - 131ms/epoch - 1ms/step\n",
            "Epoch 21/100\n",
            "94/94 - 0s - loss: 3363.8174 - 126ms/epoch - 1ms/step\n",
            "Epoch 22/100\n",
            "94/94 - 0s - loss: 3209.3862 - 123ms/epoch - 1ms/step\n",
            "Epoch 23/100\n",
            "94/94 - 0s - loss: 3137.1069 - 158ms/epoch - 2ms/step\n",
            "Epoch 24/100\n",
            "94/94 - 0s - loss: 3085.4409 - 130ms/epoch - 1ms/step\n",
            "Epoch 25/100\n",
            "94/94 - 0s - loss: 2939.6104 - 144ms/epoch - 2ms/step\n",
            "Epoch 26/100\n",
            "94/94 - 0s - loss: 2852.7266 - 138ms/epoch - 1ms/step\n",
            "Epoch 27/100\n",
            "94/94 - 0s - loss: 2727.7278 - 125ms/epoch - 1ms/step\n",
            "Epoch 28/100\n",
            "94/94 - 0s - loss: 2650.2156 - 131ms/epoch - 1ms/step\n",
            "Epoch 29/100\n",
            "94/94 - 0s - loss: 2567.6484 - 133ms/epoch - 1ms/step\n",
            "Epoch 30/100\n",
            "94/94 - 0s - loss: 2569.5791 - 125ms/epoch - 1ms/step\n",
            "Epoch 31/100\n",
            "94/94 - 0s - loss: 2413.6431 - 138ms/epoch - 1ms/step\n",
            "Epoch 32/100\n",
            "94/94 - 0s - loss: 2266.2563 - 135ms/epoch - 1ms/step\n",
            "Epoch 33/100\n",
            "94/94 - 0s - loss: 2257.5930 - 128ms/epoch - 1ms/step\n",
            "Epoch 34/100\n",
            "94/94 - 0s - loss: 2070.5999 - 142ms/epoch - 2ms/step\n",
            "Epoch 35/100\n",
            "94/94 - 0s - loss: 2062.5581 - 140ms/epoch - 1ms/step\n",
            "Epoch 36/100\n",
            "94/94 - 0s - loss: 1952.9945 - 129ms/epoch - 1ms/step\n",
            "Epoch 37/100\n",
            "94/94 - 0s - loss: 1881.2540 - 139ms/epoch - 1ms/step\n",
            "Epoch 38/100\n",
            "94/94 - 0s - loss: 1779.0146 - 144ms/epoch - 2ms/step\n",
            "Epoch 39/100\n",
            "94/94 - 0s - loss: 1795.4832 - 131ms/epoch - 1ms/step\n",
            "Epoch 40/100\n",
            "94/94 - 0s - loss: 1668.9022 - 129ms/epoch - 1ms/step\n",
            "Epoch 41/100\n",
            "94/94 - 0s - loss: 1563.7828 - 146ms/epoch - 2ms/step\n",
            "Epoch 42/100\n",
            "94/94 - 0s - loss: 1573.0535 - 145ms/epoch - 2ms/step\n",
            "Epoch 43/100\n",
            "94/94 - 0s - loss: 1463.9757 - 142ms/epoch - 2ms/step\n",
            "Epoch 44/100\n",
            "94/94 - 0s - loss: 1452.8691 - 132ms/epoch - 1ms/step\n",
            "Epoch 45/100\n",
            "94/94 - 0s - loss: 1405.4918 - 145ms/epoch - 2ms/step\n",
            "Epoch 46/100\n",
            "94/94 - 0s - loss: 1436.4678 - 136ms/epoch - 1ms/step\n",
            "Epoch 47/100\n",
            "94/94 - 0s - loss: 1399.5046 - 138ms/epoch - 1ms/step\n",
            "Epoch 48/100\n",
            "94/94 - 0s - loss: 1246.7529 - 152ms/epoch - 2ms/step\n",
            "Epoch 49/100\n",
            "94/94 - 0s - loss: 1273.6078 - 147ms/epoch - 2ms/step\n",
            "Epoch 50/100\n",
            "94/94 - 0s - loss: 1218.2526 - 137ms/epoch - 1ms/step\n",
            "Epoch 51/100\n",
            "94/94 - 0s - loss: 1214.9836 - 139ms/epoch - 1ms/step\n",
            "Epoch 52/100\n",
            "94/94 - 0s - loss: 1063.4437 - 126ms/epoch - 1ms/step\n",
            "Epoch 53/100\n",
            "94/94 - 0s - loss: 990.2430 - 155ms/epoch - 2ms/step\n",
            "Epoch 54/100\n",
            "94/94 - 0s - loss: 1070.8251 - 141ms/epoch - 2ms/step\n",
            "Epoch 55/100\n",
            "94/94 - 0s - loss: 1000.8522 - 136ms/epoch - 1ms/step\n",
            "Epoch 56/100\n",
            "94/94 - 0s - loss: 882.4382 - 143ms/epoch - 2ms/step\n",
            "Epoch 57/100\n",
            "94/94 - 0s - loss: 880.9621 - 136ms/epoch - 1ms/step\n",
            "Epoch 58/100\n",
            "94/94 - 0s - loss: 780.4167 - 132ms/epoch - 1ms/step\n",
            "Epoch 59/100\n",
            "94/94 - 0s - loss: 780.3332 - 136ms/epoch - 1ms/step\n",
            "Epoch 60/100\n",
            "94/94 - 0s - loss: 764.9612 - 146ms/epoch - 2ms/step\n",
            "Epoch 61/100\n",
            "94/94 - 0s - loss: 763.9113 - 142ms/epoch - 2ms/step\n",
            "Epoch 62/100\n",
            "94/94 - 0s - loss: 690.9128 - 143ms/epoch - 2ms/step\n",
            "Epoch 63/100\n",
            "94/94 - 0s - loss: 716.4791 - 138ms/epoch - 1ms/step\n",
            "Epoch 64/100\n",
            "94/94 - 0s - loss: 649.1371 - 133ms/epoch - 1ms/step\n",
            "Epoch 65/100\n",
            "94/94 - 0s - loss: 585.8572 - 136ms/epoch - 1ms/step\n",
            "Epoch 66/100\n",
            "94/94 - 0s - loss: 593.0674 - 138ms/epoch - 1ms/step\n",
            "Epoch 67/100\n",
            "94/94 - 0s - loss: 648.3826 - 162ms/epoch - 2ms/step\n",
            "Epoch 68/100\n",
            "94/94 - 0s - loss: 603.2034 - 141ms/epoch - 2ms/step\n",
            "Epoch 69/100\n",
            "94/94 - 0s - loss: 524.7552 - 143ms/epoch - 2ms/step\n",
            "Epoch 70/100\n",
            "94/94 - 0s - loss: 542.0290 - 151ms/epoch - 2ms/step\n",
            "Epoch 71/100\n",
            "94/94 - 0s - loss: 470.6973 - 143ms/epoch - 2ms/step\n",
            "Epoch 72/100\n",
            "94/94 - 0s - loss: 867.9154 - 159ms/epoch - 2ms/step\n",
            "Epoch 73/100\n",
            "94/94 - 0s - loss: 537.4833 - 148ms/epoch - 2ms/step\n",
            "Epoch 74/100\n",
            "94/94 - 0s - loss: 621.0460 - 217ms/epoch - 2ms/step\n",
            "Epoch 75/100\n",
            "94/94 - 0s - loss: 601.0421 - 245ms/epoch - 3ms/step\n",
            "Epoch 76/100\n",
            "94/94 - 0s - loss: 654.5172 - 237ms/epoch - 3ms/step\n",
            "Epoch 77/100\n",
            "94/94 - 0s - loss: 617.0353 - 193ms/epoch - 2ms/step\n",
            "Epoch 78/100\n",
            "94/94 - 0s - loss: 2782.6956 - 207ms/epoch - 2ms/step\n",
            "Epoch 79/100\n",
            "94/94 - 0s - loss: 825.2402 - 212ms/epoch - 2ms/step\n",
            "Epoch 80/100\n",
            "94/94 - 0s - loss: 1544.3986 - 215ms/epoch - 2ms/step\n",
            "Epoch 81/100\n",
            "94/94 - 0s - loss: 745.9886 - 186ms/epoch - 2ms/step\n",
            "Epoch 82/100\n",
            "94/94 - 0s - loss: 1625.8051 - 188ms/epoch - 2ms/step\n",
            "Epoch 83/100\n",
            "94/94 - 0s - loss: 1115.4342 - 229ms/epoch - 2ms/step\n",
            "Epoch 84/100\n",
            "94/94 - 0s - loss: 1485.4032 - 210ms/epoch - 2ms/step\n",
            "Epoch 85/100\n",
            "94/94 - 0s - loss: 5684.9155 - 205ms/epoch - 2ms/step\n",
            "Epoch 86/100\n",
            "94/94 - 0s - loss: 15255.2227 - 182ms/epoch - 2ms/step\n",
            "Epoch 87/100\n",
            "94/94 - 0s - loss: 4055.2227 - 190ms/epoch - 2ms/step\n",
            "Epoch 88/100\n",
            "94/94 - 0s - loss: 19415.8965 - 228ms/epoch - 2ms/step\n",
            "Epoch 89/100\n",
            "94/94 - 0s - loss: 10697.2324 - 219ms/epoch - 2ms/step\n",
            "Epoch 90/100\n",
            "94/94 - 0s - loss: 718.9099 - 215ms/epoch - 2ms/step\n",
            "Epoch 91/100\n",
            "94/94 - 0s - loss: 17823.0918 - 185ms/epoch - 2ms/step\n",
            "Epoch 92/100\n",
            "94/94 - 0s - loss: 1033.2992 - 199ms/epoch - 2ms/step\n",
            "Epoch 93/100\n",
            "94/94 - 0s - loss: 20896.5449 - 212ms/epoch - 2ms/step\n",
            "Epoch 94/100\n",
            "94/94 - 0s - loss: 4735.0815 - 194ms/epoch - 2ms/step\n",
            "Epoch 95/100\n",
            "94/94 - 0s - loss: 1276.8888 - 193ms/epoch - 2ms/step\n",
            "Epoch 96/100\n",
            "94/94 - 0s - loss: 2243.4766 - 201ms/epoch - 2ms/step\n",
            "Epoch 97/100\n",
            "94/94 - 0s - loss: 1716.6677 - 192ms/epoch - 2ms/step\n",
            "Epoch 98/100\n",
            "94/94 - 0s - loss: 986.2053 - 257ms/epoch - 3ms/step\n",
            "Epoch 99/100\n",
            "94/94 - 0s - loss: 3108.6296 - 243ms/epoch - 3ms/step\n",
            "Epoch 100/100\n",
            "94/94 - 0s - loss: 61535.8672 - 182ms/epoch - 2ms/step\n",
            "94/94 [==============================] - 0s 1ms/step\n",
            "Predictions [[-305.00415 ]\n",
            " [-141.29126 ]\n",
            " [-229.61353 ]\n",
            " [-289.5901  ]\n",
            " [ -45.8274  ]\n",
            " [ -29.813726]\n",
            " [ -27.717047]\n",
            " [-132.67798 ]\n",
            " [-153.2893  ]\n",
            " [-151.6643  ]]\n",
            "Final Score:  234.86567911792721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Simple Classification using Tensorflow\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import requests\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "file_path = \"/content/sample_data/IRIS.csv\"\n",
        "df = pd.read_csv(file_path, skiprows = 1, na_values = ['NA', '?'])\n",
        "column_names = ['sepal_l', 'sepal_w', 'petal_l', 'petal_w', 'species']\n",
        "df.columns = column_names\n",
        "\n",
        "#Convert to NumPy Classification\n",
        "x = df[['sepal_l', 'sepal_w', 'petal_l', 'petal_w']].values\n",
        "dummies = pd.get_dummies(df['species'])\n",
        "species = dummies.columns\n",
        "y = dummies.values\n",
        "\n",
        "#Building Neural Network\n",
        "model = Sequential()\n",
        "model.add(Dense(50, input_dim = x.shape[1], activation = 'relu')) #Hidden 1\n",
        "model.add(Dense(25, activation = 'relu')) #Hidden 2\n",
        "model.add(Dense(y.shape[1], activation = 'softmax')) #Output\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
        "model.fit(x, y, verbose = 2, epochs = 100)\n",
        "\n",
        "#Predicting the output\n",
        "pred = model.predict(x)\n",
        "predict_classes = np.argmax(pred, axis = 1)\n",
        "expected_classes = np.argmax(y, axis = 1)\n",
        "print(\"Predictions: \", predict_classes)\n",
        "print(\"Expected Classes: \", expected_classes)\n"
      ],
      "metadata": {
        "id": "7WggxNqoHz0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving and Loading Neural Networks\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import os\n",
        "import requests\n",
        "from sklearn import metrics\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "\n",
        "save_path = '.'\n",
        "\n",
        "file_path = \"/content/sample_data/IRIS.csv\"\n",
        "df = pd.read_csv(file_path, skiprows = 1, na_values = ['NA', '?'])\n",
        "column_names = ['sepal_l', 'sepal_w', 'petal_l', 'petal_w', 'species']\n",
        "df.columns = column_names\n",
        "\n",
        "# Handling missing values\n",
        "df['sepal_l'] = df['sepal_l'].fillna(df['sepal_l'].median())\n",
        "\n",
        "#Pandas to NumPy\n",
        "x = df[['sepal_l', 'sepal_w', 'petal_l', 'petal_w']].values\n",
        "dummies = pd.get_dummies(df['species'])\n",
        "species = dummies.columns\n",
        "y = dummies.values\n",
        "\n",
        "#Buliding the Neural Network\n",
        "model = Sequential()\n",
        "model.add(Dense(50, input_dim = x.shape[1], activation = 'relu')) #Hidden 1\n",
        "model.add(Dense(25, activation = 'relu')) #Hidden 2\n",
        "model.add(Dense(y.shape[1], activation = 'softmax')) #Output\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
        "model.fit(x, y, verbose = 2, epochs = 200)\n",
        "\n",
        "#Predicting the output values\n",
        "pred = model.predict(x)\n",
        "\n",
        "#Measure RMSE error\n",
        "score = np.sqrt(metrics.mean_squared_error(pred, y))\n",
        "print(score)\n",
        "\n",
        "#Saving NN to Json file\n",
        "model_json = model.to_json()\n",
        "with open(os.path.join(save_path, 'network.json'), 'w') as json_file:\n",
        "  json_file.write(model_json)\n",
        "\n",
        "#Saving NN to Yaml file\n",
        "model_yaml = model.to_json()\n",
        "with open(os.path.join(save_path, 'network.yaml'), 'w') as yaml_file:\n",
        "  yaml_file.write(model_yaml)\n",
        "\n",
        "#Saving NN to HDF5\n",
        "model.save(os.path.join(save_path, 'network.h5'))\n",
        "\n",
        "#Reloading a saved model for reuse\n",
        "from tensorflow.keras.models import load_model\n",
        "model2 = load_model(os.path.join(save_path, 'network.h5'))\n",
        "pred = model2.predict(x)\n",
        "\n",
        "#Measure the RMSE value of the given prediction\n",
        "score = np.sqrt(metrics.mean_squared_error(pred, y))\n",
        "print('Score after loading', score)"
      ],
      "metadata": {
        "id": "3UmYbKP4RwTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Early stopping with Classification\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import os\n",
        "import requests\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/sample_data/IRIS.csv', na_values = ['NA', '?'])\n",
        "column_names = ['sepal_l', 'sepal_w', 'petal_l', 'petal_w', 'species']\n",
        "df.columns = column_names\n",
        "\n",
        "#Convert to NumPy classification\n",
        "x = df[['sepal_l', 'sepal_w', 'petal_l', 'petal_w']]\n",
        "dummies = pd.get_dummies(df['species'])\n",
        "species = dummies.columns\n",
        "y = dummies.values\n",
        "\n",
        "#Split into validation and training sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 42)\n",
        "\n",
        "#Build Neural Network\n",
        "model = Sequential()\n",
        "model.add(Dense(50, input_dim = x.shape[1], activation = 'relu'))\n",
        "model.add(Dense(25, activation = 'relu'))\n",
        "model.add(Dense(y.shape[1], activation = 'softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
        "\n",
        "monitor = EarlyStopping(monitor = 'val_loss', min_delta = 1e-3, patience = 5, verbose = 1, mode = 'auto', restore_best_weights= True)\n",
        "model.fit(x_train, y_train, validation_data = (x_test, y_test), callbacks = [monitor], verbose = 2, epochs = 1000)\n",
        "\n"
      ],
      "metadata": {
        "id": "kb1QP0nozN95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Early Stopping with Regression\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "df = pd.read_csv('/content/sample_data/IRIS.csv', na_values = ['NA', '?'])\n",
        "column_names = ['sepal_l', 'sepal_w', 'petal_l', 'petal_w', 'species']\n",
        "df.columns = column_names\n",
        "\n",
        "#Convert to NumPy classification\n",
        "x = df[['sepal_l', 'sepal_w', 'petal_l', 'petal_w']]\n",
        "dummies = pd.get_dummies(df['species'])\n",
        "species = dummies.columns\n",
        "y = dummies.values[: , 1]\n",
        "\n",
        "#Splitting into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 42)\n",
        "\n",
        "#Building the Neural Network\n",
        "model = Sequential()\n",
        "model.add(Dense(25, input_dim = x.shape[1], activation = 'relu'))\n",
        "model.add(Dense(10, activation = 'relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
        "\n",
        "monitor = EarlyStopping(monitor = 'val_loss', min_delta = 1e-3, patience = 5, verbose = 1, mode = 'auto', restore_best_weights= True)\n",
        "model.fit(x_train, y_train, validation_data = (x_test, y_test), callbacks = [monitor], verbose = 2, epochs = 1000)\n",
        "\n",
        "#Predicting the output\n",
        "pred = model.predict(x_test)\n",
        "score = np.sqrt(metrics.mean_squared_error(pred, y_test))\n",
        "print('Final Score: ', score)"
      ],
      "metadata": {
        "id": "Ut8E9HQv3coH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Manual Neural Network Calculation of XOR function\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Create a dataset for the XOR function\n",
        "x = np.array([[0,0], [1,0], [0,1], [1,1]])\n",
        "y = np.array([0, 1, 1, 0])\n",
        "\n",
        "#Building the Neural Network\n",
        "done = False\n",
        "cycle = 1\n",
        "\n",
        "#Change this to while not done\n",
        "while not done:\n",
        "  print('Cycle', cycle)\n",
        "  cycle = cycle + 1\n",
        "  model = Sequential()\n",
        "  model.add(Dense(2, input_dim = 2, activation = 'relu'))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
        "  model.fit(x, y, verbose = 0, epochs = 10000)\n",
        "\n",
        "#Predicting the output\n",
        "pred = model.predict(x)\n",
        "\n",
        "done = pred[0] < 0.01 and pred[3] < 0.01 and pred[1] > 0.9 and pred[2] > 0.9\n",
        "print(pred)\n",
        "\n",
        "#Dump Weights\n",
        "for layerNum, layer in enumerate(model.layers):\n",
        "  weights = layer.get_weights()[0]\n",
        "  biases = layer.get_weights()[1]\n",
        "\n",
        "  for toNeuronNum, bias in enumerate(biases):\n",
        "    print(layerNum, ' ->', layerNum+1, toNeuronNum, ':', bias)\n",
        "\n",
        "  for fromNeuronNum, wgt in enumerate(weights):\n",
        "    for toNeuronNum, wgt2 in enumerate(wgt):\n",
        "      print(layerNum, ' ', fromNeuronNum, '->', layerNum+1, ' ', toNeuronNum, '=', wgt2)\n"
      ],
      "metadata": {
        "id": "2pCNixY_8B5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MandelBrot Set Example\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import PIL.Image\n",
        "from io import BytesIO\n",
        "from IPython.display import Image, display\n",
        "\n",
        "def DisplayFractal(a, fmt = 'jpeg'):\n",
        "  a_cyclic = (6.28*a/20.0).reshape(list(a.shape) + [1])\n",
        "  img = np.concatenate([10 + 20*np.cos(a_cyclic), 3- + 50*np.sin(a_cyclic), 155 - 80*np.cos(a_cyclic)], 2)\n",
        "  img[a == a.max()] = 0\n",
        "  a = img\n",
        "  a = np.uint8(np.clip(a, 0, 255))\n",
        "  f = BytesIO()\n",
        "  PIL.Image.fromarray(a).save(f, fmt)\n",
        "  display(Image(data = f.getvalue()))\n",
        "\n",
        "#Use NumPy to create a 2-D array of Complex Numbers\n",
        "Y, X = np.mgrid[-1.3: 1.3: 0.005, -2: 1: 0.005]\n",
        "Z = X + 1j*Y\n",
        "\n",
        "xs = tf.constant(Z.astype(np.complex64))\n",
        "zs = tf.Variable(xs)\n",
        "ns = tf.Variable(tf.zeros_like(xs, tf.float32))\n",
        "\n",
        "for i in range(200):\n",
        "  zs_ = zs*zs + xs\n",
        "\n",
        "  not_diverged = tf.abs(zs_) < 4\n",
        "  zs.assign(zs_)\n",
        "  ns.assign_add(tf.cast(not_diverged, tf.float32))\n",
        "\n",
        "DisplayFractal(ns.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "OGE_83sNMMX-",
        "outputId": "146481e4-bfae-444a-80a1-141ccd0d867f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}